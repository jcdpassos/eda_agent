import streamlit as st
import pandas as pd
import os
from dotenv import load_dotenv # <-- 1. IMPORTAR a biblioteca dotenv
from langchain_experimental.agents import create_pandas_dataframe_agent
from langchain_google_genai import ChatGoogleGenerativeAI

# --- Carregar VariÃ¡veis de Ambiente ---
# Carrega as variÃ¡veis do arquivo .env para o ambiente do sistema
load_dotenv() 

# --- ConfiguraÃ§Ãµes Iniciais da PÃ¡gina ---
st.set_page_config(
    page_title="Agente de AnÃ¡lise de Dados",
    page_icon="ðŸ¤–",
    layout="wide"
)

st.title("ðŸ¤– Agente de AnÃ¡lise de Dados com Gemini")
st.markdown("""
Bem-vindo! FaÃ§a o upload de um arquivo CSV e comece a fazer perguntas sobre seus dados. 
O agente pode gerar descriÃ§Ãµes, anÃ¡lises e grÃ¡ficos para vocÃª.
""")

# --- Obter a chave de API do ambiente ---
google_api_key = os.getenv("GOOGLE_API_KEY") # <-- 2. LER a chave do ambiente

# --- Sidebar para Upload ---
with st.sidebar:
    st.header("ConfiguraÃ§Ãµes")
    # O input da chave de API foi REMOVIDO daqui para seguranÃ§a.
    uploaded_file = st.file_uploader("FaÃ§a o upload do seu arquivo CSV", type=["csv"])

# --- LÃ³gica principal da aplicaÃ§Ã£o ---
# Verifica se a chave foi carregada e se um arquivo foi enviado
if not google_api_key:
    st.error("A chave de API do Google (GOOGLE_API_KEY) nÃ£o foi encontrada.")
    st.info("Por favor, crie um arquivo .env e adicione sua chave de API nele.")
elif uploaded_file is None:
    st.info("Por favor, faÃ§a o upload de um arquivo CSV para comeÃ§ar.")
else:
    try:
        # Carregar os dados
        df = pd.read_csv(uploaded_file)
        st.success("Arquivo CSV carregado com sucesso! Veja uma amostra dos dados abaixo:")
        st.dataframe(df.head())

        # --- InicializaÃ§Ã£o do Agente ---
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp", 
            google_api_key=google_api_key, # A chave agora vem da variÃ¡vel
            temperature=0.2
        )

        agent = create_pandas_dataframe_agent(
            llm, 
            df, 
            verbose=True,
            agent_executor_kwargs={"handle_parsing_errors": True},
            allow_dangerous_code=True 
        )

        # --- ImplementaÃ§Ã£o da MemÃ³ria e do Chat ---
        if "memory" not in st.session_state:
            st.session_state.memory = ""

        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("FaÃ§a sua pergunta sobre os dados..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            full_prompt = f"""
            HistÃ³rico da conversa anterior:
            {st.session_state.memory}

            Pergunta do usuÃ¡rio: {prompt}
            
            InstruÃ§Ãµes importantes: Responda em portuguÃªs do Brasil.
            """

            with st.chat_message("assistant"):
                with st.spinner("O agente estÃ¡ pensando... ðŸ¤”"):
                    try:
                        response = agent.invoke({"input": full_prompt})
                        st.markdown(response['output'])
                        
                        st.session_state.messages.append({"role": "assistant", "content": response['output']})
                        st.session_state.memory += f"\nUsuÃ¡rio: {prompt}\nAgente: {response['output']}"

                    except Exception as e:
                        st.error(f"Ocorreu um erro ao processar sua pergunta: {e}")

    except Exception as e:
        st.error(f"Ocorreu um erro ao carregar o arquivo: {e}")